{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61npX6ajxxej"
   },
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jG04tIcvn8-k"
   },
   "source": [
    "![alt text](https://cdn-media-1.freecodecamp.org/images/qRGh8boBcLLQfBvDnWTXKxZIEAk5LNfNABHF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyKhu535oK8Z"
   },
   "source": [
    "Bag of Words (BOW) is a method to extract features from text documents. These features can be used for training machine learning algorithms. It creates a vocabulary of all the unique words occurring in all the documents in the training set.\n",
    "\n",
    "In simple terms, it’s a collection of words to represent a sentence with word count and mostly disregarding the order in which they appear.\n",
    "\n",
    "BOW is an approach widely used with:\n",
    "\n",
    "* Natural language processing\n",
    "* Information retrieval from documents\n",
    "* Document classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbeniDfMoW2m"
   },
   "source": [
    "Let’s start with an example to understand by taking some sentences and generating vectors for those.\n",
    "\n",
    "1. \"John likes to watch movies. Mary likes movies too.\"\n",
    "2. \"John also likes to watch football games.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsAWDjr_oiXv"
   },
   "source": [
    "Further, for each sentence, remove multiple occurrences of the word and use the word count to represent this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "ZjCMcVOHnvtQ",
    "outputId": "7f058a51-2dff-42a5-facb-5cc5c49e090c"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c63413d58278>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1. {\"John\":1,\"likes\":2,\"to\":1,\"watch\":1,\"movies\":2,\"Mary\":1,\"too\":1}\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1. {\"John\":1,\"likes\":2,\"to\":1,\"watch\":1,\"movies\":2,\"Mary\":1,\"too\":1}\n",
    "2. {\"John\":1,\"also\":1,\"likes\":1,\"to\":1,\"watch\":1,\"football\":1,\"games\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJuyU6UForrJ"
   },
   "source": [
    "Assuming these sentences are part of a document, below is the combined word frequency for our entire document. Both sentences are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ri81-fGot1V"
   },
   "outputs": [],
   "source": [
    "{\"John\":2,\"likes\":3,\"to\":2,\"watch\":2,\"movies\":2,\"Mary\":1,\"too\":1,  \"also\":1,\"football\":1,\"games\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS2q4K9MsVY9"
   },
   "source": [
    "**The length of the vector will always be equal to vocabulary size. In this case the vector length is 11.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUxIFxlRsgLk"
   },
   "source": [
    "In order to represent our original sentences in a vector, each vector is initialized with all zeros — [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "This is followed by iteration and comparison with each word in our vocabulary, and incrementing the vector value if the sentence has that word.\n",
    "\n",
    "John likes to watch movies. Mary likes movies too.[1, 2, 1, 1, 2, 1, 1, 0, 0, 0]\n",
    "John also likes to watch football games.[1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "For example, in sentence 1 the word likes appears in second position and appears two times. So the second element of our vector for sentence 1 will be 2: [1, 2, 1, 1, 2, 1, 1, 0, 0, 0]\n",
    "\n",
    "The vector is always proportional to the size of our vocabulary.\n",
    "\n",
    "A big document where the generated vocabulary is huge may result in a vector with lots of 0 values. This is called a sparse vector. Sparse vectors require more memory and computational resources when modeling. The vast number of positions or dimensions can make the modeling process very challenging for traditional algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "XF_CFDB8o5ql",
    "outputId": "4e8350e9-c70c-4294-fab4-b232a5d11031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word List for Document \n",
      "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'took', 'train', 'until', 'waited', 'was'] \n",
      "\n",
      "joe waited for the train \n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "\n",
      "the train was late \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "\n",
      "mary and samantha took the bus \n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "i looked for mary and samantha at the bus station \n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "mary and samantha arrived at the bus station early but waited until noon for the bus \n",
      "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.feature_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fdfb149ffd3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# or one can use sklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallsentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.feature_extraction'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import re\n",
    "\n",
    "'''\n",
    "Tokenize each the sentences, example\n",
    "Input : \"John likes to watch movies. Mary likes movies too\"\n",
    "Ouput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
    "'''\n",
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = word_extraction(sentence)\n",
    "        words.extend(w)\n",
    "        \n",
    "    words = sorted(list(set(words)))\n",
    "    return words\n",
    "\n",
    "def word_extraction(sentence):\n",
    "    ignore = ['a', \"the\", \"is\"]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
    "    return cleaned_text    \n",
    "    \n",
    "def generate_bow(allsentences):    \n",
    "    vocab = tokenize(allsentences)\n",
    "    print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "\n",
    "    for sentence in allsentences:\n",
    "        words = word_extraction(sentence)\n",
    "        bag_vector = numpy.zeros(len(vocab))\n",
    "        for w in words:\n",
    "            for i,word in enumerate(vocab):\n",
    "                if word == w: \n",
    "                    bag_vector[i] += 1\n",
    "                    \n",
    "        print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))\n",
    "\n",
    "\n",
    "allsentences = [\"joe waited for the train\", \"the train was late\", \"mary and samantha took the bus\", \n",
    "            \"i looked for mary and samantha at the bus station\", \n",
    "            \"mary and samantha arrived at the bus station early but waited until noon for the bus\"]\n",
    "\n",
    "\n",
    "generate_bow(allsentences)\n",
    "\n",
    "# or one can use sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(allsentences)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XjyLHxfvna9"
   },
   "source": [
    "### Limitations of BOW\n",
    "\n",
    "**Semantic meaning**: the basic BOW approach does not consider the meaning of the word in the document. It completely ignores the context in which it’s used. The same word can be used in multiple places based on the context or nearby words.\n",
    "\n",
    "**Vector size**: For a large document, the vector size can be huge resulting in a lot of computation and time. You may need to ignore words based on relevance to your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AggHl0qqxtV0"
   },
   "source": [
    "## Bi-gram / N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "LyVMK1hxzJ6L",
    "outputId": "428ad557-90da-4e60-d451-24185e942350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "DXk0ashjzU8Q",
    "outputId": "5050350a-2d58-4abd-cd6a-b3748dea5cf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS5_8cdvzFeE"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "word_list = []\n",
    "\n",
    "# Set up a quick lookup table for common words like \"the\" and \"an\" so they can be excluded\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# For all 18 novels in the public domain book corpus, extract all their words\n",
    "[word_list.extend(nltk.corpus.gutenberg.words(f)) for f in nltk.corpus.gutenberg.fileids()]\n",
    "\n",
    "# Filter out words that have punctuation and make everything lower-case\n",
    "cleaned_words = [w.lower() for w in word_list if w.isalnum()]\n",
    "\n",
    "# Ask NLTK to generate a list of bigrams for the word \"sun\", excluding \n",
    "# those words which are too common to be interesing \n",
    "sun_bigrams = [b for b in nltk.bigrams(cleaned_words) if (b[0] == 'sun' or b[1] == 'sun') \\\n",
    "  and b[0] not in stops and b[1] not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "WemP6_ULzpTt",
    "outputId": "1295c394-4af9-453e-bb49-f3c89f191279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('day', 'sun'), ('glaring', 'sun'), ('sun', 'tired'), ('sun', 'bright'), ('sun', 'appeared'), ('western', 'sun'), ('rising', 'sun'), ('sun', 'frequently'), ('sun', 'gained'), ('sun', 'went'), ('sun', 'rose'), ('sun', 'waxed'), ('sun', '17'), ('sun', 'goeth'), ('sun', 'shall'), ('sun', 'goeth'), ('sun', 'goeth'), ('sun', 'go'), ('sun', 'shall'), ('israel', 'sun'), ('sun', 'stand'), ('sun', 'stood'), ('sun', 'stood'), ('sun', 'went'), ('sun', 'went'), ('sun', 'went'), ('sun', '12'), ('sun', '12'), ('sun', 'riseth'), ('sun', 'saying'), ('sun', 'shone'), ('sun', 'going'), ('sun', '19'), ('sun', 'unto'), ('sun', '58'), ('sun', '74'), ('sun', 'knoweth'), ('sun', 'ariseth'), ('sun', 'unto'), ('sun', 'shall'), ('sun', '1'), ('sun', 'also'), ('sun', 'goeth'), ('sun', '1'), ('sun', '2'), ('sun', '2'), ('sun', '2'), ('sun', '4'), ('sun', '4'), ('sun', 'namely'), ('sun', '7'), ('sun', '7'), ('sun', '8'), ('sun', '9'), ('sun', '9'), ('sun', '11'), ('sun', 'hath'), ('sun', 'shall'), ('sun', 'ashamed'), ('sun', 'shall'), ('sun', 'dial'), ('sun', 'returned'), ('sun', 'shall'), ('sun', 'smite'), ('sun', 'shall'), ('thy', 'sun'), ('sun', 'shall'), ('sun', 'toward'), ('sun', 'shall'), ('sun', 'beat'), ('sun', 'shall'), ('sun', 'ariseth'), ('sun', 'even'), ('sun', 'shall'), ('sun', '16'), ('sun', 'shall'), ('sun', 'shining'), ('neither', 'sun'), ('sun', 'go'), ('sun', 'shineth'), ('sun', 'became'), ('sun', 'light'), ('sun', 'neither'), ('rising', 'sun'), ('sun', 'descending'), ('sun', 'seeking'), ('rising', 'sun'), ('risen', 'sun'), ('sun', 'till'), ('sun', 'said'), ('sun', 'burned'), ('mother', 'sun'), ('sun', 'carefully'), ('sun', 'instantly'), ('sun', 'bonnet'), ('sun', 'rose'), ('setting', 'sun'), ('blazing', 'sun'), ('sun', 'shone'), ('mr', 'sun'), ('mr', 'sun'), ('sun', 'thought'), ('mr', 'sun'), ('mr', 'sun'), ('mr', 'sun'), ('mr', 'sun'), ('sun', 'climbed'), ('setting', 'sun'), ('lucifer', 'sun'), ('sun', 'turned'), ('white', 'sun'), ('sun', 'stood'), ('sun', 'something'), ('sun', 'never'), ('victorious', 'sun'), ('sun', 'swept'), ('sun', 'evan'), ('victorious', 'sun'), ('sun', 'sinking'), ('sun', 'whether'), ('sun', 'ran'), ('sun', 'turnbull'), ('sun', 'turnbull'), ('sun', 'things'), ('haired', 'sun'), ('sun', 'burnt'), ('western', 'sun'), ('sun', 'also'), ('sun', 'would'), ('sun', 'threw'), ('western', 'sun'), ('western', 'sun'), ('sun', 'dalroy'), ('western', 'sun'), ('western', 'sun'), ('sun', 'gave'), ('western', 'sun'), ('sun', 'like'), ('red', 'sun'), ('weaker', 'sun'), ('strong', 'sun'), ('sun', 'soaked'), ('sun', 'splashed'), ('afternoon', 'sun'), ('setting', 'sun'), ('golden', 'sun'), ('setting', 'sun'), ('sun', 'cast'), ('setting', 'sun'), ('sun', 'shone'), ('sun', 'rose'), ('sun', 'shone'), ('sun', 'shines'), ('sun', 'upon'), ('sun', 'besides'), ('setting', 'sun'), ('sun', 'shining'), ('hot', 'sun'), ('sun', 'shining'), ('sun', 'lit'), ('sun', 'toasted'), ('sun', 'lit'), ('pleasant', 'sun'), ('sun', 'two'), ('sun', 'entered'), ('pleasant', 'sun'), ('torrid', 'sun'), ('sun', 'like'), ('sun', 'rise'), ('sun', 'set'), ('ratifying', 'sun'), ('diver', 'sun'), ('sun', 'slow'), ('spangling', 'sun'), ('sun', 'shifted'), ('modern', 'sun'), ('sun', 'ever'), ('burnished', 'sun'), ('sun', 'glade'), ('sultry', 'sun'), ('sun', 'ahab'), ('seeing', 'sun'), ('slanting', 'sun'), ('sun', 'playing'), ('upper', 'sun'), ('hump', 'sun'), ('sun', 'dried'), ('blazing', 'sun'), ('running', 'sun'), ('poor', 'sun'), ('sun', 'burnt'), ('sun', 'another'), ('natural', 'sun'), ('glad', 'sun'), ('sun', 'hides'), ('sun', 'hides'), ('equatorial', 'sun'), ('volcanoes', 'sun'), ('keystone', 'sun'), ('sun', 'entering'), ('coined', 'sun'), ('sun', 'wears'), ('bright', 'sun'), ('sun', 'meets'), ('great', 'sun'), ('sun', 'goes'), ('sun', 'stands'), ('blinding', 'sun'), ('great', 'sun'), ('sun', 'seemed'), ('abated', 'sun'), ('sun', 'afloat'), ('sky', 'sun'), ('sun', 'oh'), ('quickening', 'sun'), ('japanese', 'sun'), ('sun', 'seems'), ('thou', 'sun'), ('sun', 'science'), ('sun', 'level'), ('invisible', 'sun'), ('bright', 'sun'), ('sun', 'ho'), ('sun', 'astern'), ('sun', 'rise'), ('sun', 'come'), ('sun', 'seemed'), ('great', 'sun'), ('sun', 'move'), ('sun', 'moby'), ('earliest', 'sun'), ('sun', 'chapter'), ('sun', 'aye'), ('ye', 'sun'), ('sun', 'moon'), ('sun', 'new'), ('setting', 'sun'), ('sun', 'dropt'), ('radiant', 'sun'), ('rising', 'sun'), ('sun', 'gilds'), ('golden', 'sun'), ('chemick', 'sun'), ('sun', 'shine'), ('blazing', 'sun'), ('morning', 'sun'), ('sun', 'first'), ('sun', 'declined'), ('setting', 'sun'), ('sun', 'slowly'), ('sun', 'beam'), ('rising', 'sun'), ('thou', 'sun'), ('orient', 'sun'), ('sun', 'paint'), ('mounted', 'sun'), ('sun', 'shot'), ('sun', 'hath'), ('sun', 'impearls'), ('sun', 'bright'), ('sun', 'predominant'), ('sun', 'soon'), ('thou', 'sun'), ('sun', 'said'), ('parting', 'sun'), ('sun', 'beyond'), ('sun', 'descried'), ('sun', 'producing'), ('sun', 'light'), ('sun', 'ingendered'), ('low', 'sun'), ('clear', 'sun'), ('sun', 'shall'), ('commanding', 'sun'), ('th', 'sun'), ('sun', 'queen'), ('sun', 'breed'), ('sun', 'see'), ('sun', 'usher'), ('bearded', 'sun'), ('sun', 'burnt'), ('sun', 'falls'), ('sun', 'rise'), ('send', 'sun'), ('sun', 'rise'), ('downward', 'sun'), ('sun', 'ever'), ('sun', 'making'), ('runaway', 'sun'), ('mounting', 'sun'), ('sun', 'ever'), ('sun', 'rise'), ('sun', 'wheels'), ('midnight', 'sun'), ('west', 'sun'), ('sun', 'half'), ('gayety', 'sun'), ('sun', 'tan'), ('setting', 'sun'), ('summer', 'sun'), ('sun', 'shining'), ('sun', 'moon'), ('summer', 'sun'), ('sun', 'embracing'), ('immense', 'sun'), ('sun', 'action'), ('sun', 'swings'), ('great', 'sun'), ('flashing', 'sun'), ('red', 'sun'), ('hot', 'sun'), ('sun', 'shining'), ('sun', 'measuring'), ('afternoon', 'sun'), ('sun', 'shines'), ('coming', 'sun'), ('sun', 'hark'), ('rising', 'sun'), ('silent', 'sun'), ('sun', '1'), ('silent', 'sun'), ('silent', 'sun'), ('sun', 'keep'), ('dazzling', 'sun'), ('sun', 'around'), ('hot', 'sun'), ('sinking', 'sun'), ('sun', 'burning'), ('excellent', 'sun'), ('sun', 'failing'), ('earth', 'sun'), ('sun', 'animals'), ('beaming', 'sun'), ('sun', 'excludes'), ('sun', 'following'), ('sun', 'bright'), ('rising', 'sun'), ('sun', 'rose'), ('sun', 'bursts'), ('needed', 'sun'), ('sun', 'radiant'), ('bright', 'sun'), ('sun', 'shining'), ('shining', 'sun'), ('sun', 'moon'), ('sun', 'usher'), ('setting', 'sun'), ('sun', 'though'), ('sheeny', 'sun'), ('sun', 'wilt'), ('afternoon', 'sun'), ('sun', 'moon'), ('forenoon', 'sun'), ('sun', 'freighted'), ('sun', 'thy'), ('sun', 'stars'), ('midday', 'sun'), ('sun', 'set')]\n",
      "358\n"
     ]
    }
   ],
   "source": [
    "print(sun_bigrams)\n",
    "print(len(sun_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "biHZ6yaX0EAv",
    "outputId": "98d82926-b831-498e-ef9b-12104d24e5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3feHxbLz_pp"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams \n",
    "\n",
    "sentences = [\"To Sherlock Holmes she is always the woman.\", \"I have seldom heard him mention her under any other name.\"]\n",
    "\n",
    "bigrams = []\n",
    "for sentence in sentences:\n",
    "    sequence = word_tokenize(sentence) \n",
    "    bigrams.extend(list(ngrams(sequence, 2)))\n",
    "\n",
    "freq_dist = nltk.FreqDist(bigrams)\n",
    "prob_dist = nltk.MLEProbDist(freq_dist)\n",
    "number_of_bigrams = freq_dist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "tUOg5nlt0K9f",
    "outputId": "6ac45426-92b2-4565-e8c3-f6434c65bd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('To', 'Sherlock'), ('Sherlock', 'Holmes'), ('Holmes', 'she'), ('she', 'is'), ('is', 'always'), ('always', 'the'), ('the', 'woman'), ('woman', '.'), ('I', 'have'), ('have', 'seldom'), ('seldom', 'heard'), ('heard', 'him'), ('him', 'mention'), ('mention', 'her'), ('her', 'under'), ('under', 'any'), ('any', 'other'), ('other', 'name'), ('name', '.')]\n",
      "<FreqDist with 19 samples and 19 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(bigrams)\n",
    "print(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "y_KIdW26r4go",
    "outputId": "20131b57-bcdd-403c-dd68-2a1a840959e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'aware', 'that', 'nltk', 'only', 'offers', 'bigrams', 'and', 'trigrams', ',', 'but', 'is', 'there', 'a', 'way', 'to', 'split', 'my', 'text', 'in', 'four-grams', ',', 'five-grams', 'or', 'even', 'hundred-grams']\n",
      "<generator object ngrams at 0x7f8fb50f00a0>\n",
      "<generator object ngrams at 0x7f8fb2295f10>\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "text = \"I am aware that nltk only offers bigrams and trigrams, but is there a way to split my text in four-grams, five-grams or even hundred-grams\"\n",
    "tokenize = nltk.word_tokenize(text)\n",
    "print(tokenize)\n",
    "\n",
    "trigrams=ngrams(tokenize,3)\n",
    "print(trigrams)\n",
    "fourgrams=ngrams(tokenize,4)\n",
    "print(fourgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "KfRfPH_KtBue",
    "outputId": "9ff5a47c-f674-406e-9181-9f141d0e74e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am aware',\n",
       " 'am aware that',\n",
       " 'aware that nltk',\n",
       " 'that nltk only',\n",
       " 'nltk only offers',\n",
       " 'only offers bigrams',\n",
       " 'offers bigrams and',\n",
       " 'bigrams and trigrams',\n",
       " 'and trigrams ,',\n",
       " 'trigrams , but',\n",
       " ', but is',\n",
       " 'but is there',\n",
       " 'is there a',\n",
       " 'there a way',\n",
       " 'a way to',\n",
       " 'way to split',\n",
       " 'to split my',\n",
       " 'split my text',\n",
       " 'my text in',\n",
       " 'text in four-grams',\n",
       " 'in four-grams ,',\n",
       " 'four-grams , five-grams',\n",
       " ', five-grams or',\n",
       " 'five-grams or even',\n",
       " 'or even hundred-grams']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngrams(n_grams):\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "get_ngrams(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "ZyfmZItvtcvI",
    "outputId": "d5159545-ac33-43eb-bc79-5df5e75e7e01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am aware that',\n",
       " 'am aware that nltk',\n",
       " 'aware that nltk only',\n",
       " 'that nltk only offers',\n",
       " 'nltk only offers bigrams',\n",
       " 'only offers bigrams and',\n",
       " 'offers bigrams and trigrams',\n",
       " 'bigrams and trigrams ,',\n",
       " 'and trigrams , but',\n",
       " 'trigrams , but is',\n",
       " ', but is there',\n",
       " 'but is there a',\n",
       " 'is there a way',\n",
       " 'there a way to',\n",
       " 'a way to split',\n",
       " 'way to split my',\n",
       " 'to split my text',\n",
       " 'split my text in',\n",
       " 'my text in four-grams',\n",
       " 'text in four-grams ,',\n",
       " 'in four-grams , five-grams',\n",
       " 'four-grams , five-grams or',\n",
       " ', five-grams or even',\n",
       " 'five-grams or even hundred-grams']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams(fourgrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjt6AuawCbHq"
   },
   "source": [
    "## TF-IDF Vectorizer\n",
    "\n",
    "\n",
    "TF-IDF stands for term frequency-inverse document frequency. TF-IDF weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "**Term Frequency (TF)**: is a scoring of the frequency of the word in the current document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. The term frequency is often divided by the document length to normalize.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/404/1*SUAeubfQGK_w0XZWQW6V1Q.png)\n",
    "\n",
    "\n",
    "**Inverse Document Frequency (IDF)**: is a scoring of how rare the word is across documents. IDF is a measure of how rare a term is. Rarer the term, more is the IDF score.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/411/1*T57j-UDzXizqG40FUfmkLw.png)\n",
    "\n",
    "\n",
    "Thus,\n",
    "\n",
    "![alt text](https://miro.medium.com/max/215/1*YrgmAeG7KNRB4dQcGcsdyg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxNmcj76Df5b"
   },
   "source": [
    "The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "kJjoboYZwL6w",
    "outputId": "8d3a3640-b991-408d-d5a0-496241af788f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-08382bd3-4498-4654-8925-134fb7a008f2\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-08382bd3-4498-4654-8925-134fb7a008f2\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving stackoverflow-data-idf.json to stackoverflow-data-idf.json\n",
      "User uploaded file \"stackoverflow-data-idf.json\" with length 43476643 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "m2eNYFFCwCSU",
    "outputId": "b99e0fff-9be4-4a89-b146-778003444c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      " accepted_answer_id          float64\n",
      "answer_count                  int64\n",
      "body                         object\n",
      "comment_count                 int64\n",
      "community_owned_date         object\n",
      "creation_date                object\n",
      "favorite_count              float64\n",
      "id                            int64\n",
      "last_activity_date           object\n",
      "last_edit_date               object\n",
      "last_editor_display_name     object\n",
      "last_editor_user_id         float64\n",
      "owner_display_name           object\n",
      "owner_user_id               float64\n",
      "post_type_id                  int64\n",
      "score                         int64\n",
      "tags                         object\n",
      "title                        object\n",
      "view_count                    int64\n",
      "dtype: object\n",
      "Number of questions,columns= (20000, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read json into a dataframe\n",
    "df_idf=pd.read_json(\"stackoverflow-data-idf.json\",lines=True)\n",
    "\n",
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "qDT8RjbwwZxA",
    "outputId": "03560afe-eaa9-444b-b1fa-14e9801f5a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gradle command line i m trying to run a shell script with gradle i currently have something like this def test project tasks create test exec commandline bash c bash c my file dir script sh the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces '"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the first 'text'\n",
    "df_idf['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "hZY_dD836oIo",
    "outputId": "f8fe77b4-b560-474c-840c-3f9368ab8ca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-87c3671e-0005-4264-a9ed-0fe02dd1ba21\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-87c3671e-0005-4264-a9ed-0fe02dd1ba21\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving stopwords.txt to stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "EyyPBtvrwgbM",
    "outputId": "6459f80a-b80b-4218-8950-86ff9b132362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "yBMYQrrlxKH2",
    "outputId": "ee0adde6-7ac5-4536-847b-4a976a629814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 124901)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "UCfMx2VkxOWF",
    "outputId": "9a6dcd10-367d-429e-f70d-cdaafd95909e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "X8femwmsxRSp",
    "outputId": "979e5927-3f25-495d-8b6b-768a7e02709a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serializing',\n",
       " 'private',\n",
       " 'struct',\n",
       " 'public',\n",
       " 'class',\n",
       " 'contains',\n",
       " 'properties',\n",
       " 'string',\n",
       " 'serialize',\n",
       " 'attempt']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "ef-9jLnjxTt4",
    "outputId": "c3c3e10b-6134-4854-afe3-884741e1beb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customization',\n",
       " 'customize',\n",
       " 'customized',\n",
       " 'customlog',\n",
       " 'customview',\n",
       " 'cut',\n",
       " 'cv',\n",
       " 'cv_',\n",
       " 'cval',\n",
       " 'cvc',\n",
       " 'cw',\n",
       " 'cwd',\n",
       " 'cx',\n",
       " 'cx_oracle',\n",
       " 'cxf']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(cv.get_feature_names())[2000:2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2m5wAh2BxqD7",
    "outputId": "49f2e298-f464-4b29-fbe6-c1af6357440e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "FAxAwjrbxsPV",
    "outputId": "80a3dd50-f877-48fe-9652-27297a70c63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.37717703,  9.80492526,  9.51724319, ...,  8.82409601,\n",
       "       10.21039037,  9.51724319])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "PSIgkppuyZL-",
    "outputId": "7933aeb5-b389-40e2-8018-39270e8aaf85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-daec1067-e6eb-4bfd-a9e3-271a1b047b12\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-daec1067-e6eb-4bfd-a9e3-271a1b047b12\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving stackoverflow-test.json to stackoverflow-test.json\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZO76ZJAyeyM"
   },
   "outputs": [],
   "source": [
    "# read test docs into a dataframe and concatenate title and body\n",
    "df_test=pd.read_json(\"stackoverflow-test.json\",lines=True)\n",
    "df_test['text'] = df_test['title'] + df_test['body']\n",
    "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=df_test['text'].tolist()\n",
    "docs_title=df_test['title'].tolist()\n",
    "docs_body=df_test['body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JdTFJgvltor"
   },
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Lgqavv0slzE_",
    "outputId": "e368cebb-cbe1-469c-e696-859fe7c947fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Integrate War-Plugin for m2eclipse into Eclipse Project\n",
      "\n",
      "=====Body=====\n",
      "<p>I set up a small web project with JSF and Maven. Now I want to deploy on a Tomcat server. Is there a possibility to automate that like a button in Eclipse that automatically deploys the project to Tomcat?</p>\n",
      "\n",
      "<p>I read about a the <a href=\"http://maven.apache.org/plugins/maven-war-plugin/\" rel=\"nofollow noreferrer\">Maven War Plugin</a> but I couldn't find a tutorial how to integrate that into my process (eclipse/m2eclipse).</p>\n",
      "\n",
      "<p>Can you link me to help or try to explain it. Thanks.</p>\n",
      "\n",
      "===Keywords===\n",
      "eclipse 0.593\n",
      "war 0.317\n",
      "integrate 0.281\n",
      "maven 0.273\n",
      "tomcat 0.27\n",
      "project 0.239\n",
      "plugin 0.214\n",
      "automate 0.157\n",
      "jsf 0.152\n",
      "possibility 0.146\n"
     ]
    }
   ],
   "source": [
    "# you only needs to do this once\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=docs_test[0]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# now print the results\n",
    "print(\"\\n=====Title=====\")\n",
    "print(docs_title[0])\n",
    "print(\"\\n=====Body=====\")\n",
    "print(docs_body[0])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xMva08Rl5EY"
   },
   "outputs": [],
   "source": [
    "# put the common code into several methods\n",
    "def get_keywords(idx):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(docs_title[idx])\n",
    "    print(\"\\n=====Body=====\")\n",
    "    print(docs_body[idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "cwaH93fRnUmW",
    "outputId": "09228f9c-ab11-434b-c184-30ed291f9baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "SQL Import Wizard - Error\n",
      "\n",
      "=====Body=====\n",
      "<p>I have a CSV file that I'm trying to import into SQL Management Server Studio.</p>\n",
      "\n",
      "<p>In Excel, the column giving me trouble looks like this:\n",
      "<a href=\"https://i.stack.imgur.com/pm0uS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pm0uS.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>Tasks > import data > Flat Source File > select file</p>\n",
      "\n",
      "<p><a href=\"https://i.stack.imgur.com/G4b6I.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/G4b6I.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>I set the data type for this column to DT_NUMERIC, adjust the DataScale to 2 in order to get 2 decimal places, but when I click over to Preview, I see that it's clearly not recognizing the numbers appropriately:</p>\n",
      "\n",
      "<p><a href=\"https://i.stack.imgur.com/NZhiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NZhiQ.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>The column mapping for this column is set to type = decimal; precision 18; scale 2.</p>\n",
      "\n",
      "<p>Error message: Data Flow Task 1: Data conversion failed. The data conversion for column \"Amount\" returned status value 2 and status text \"The value could not be converted because of a potential loss of data.\".\n",
      " (SQL Server Import and Export Wizard)</p>\n",
      "\n",
      "<p>Can someone identify where I'm going wrong here?  Thanks!</p>\n",
      "\n",
      "===Keywords===\n",
      "column 0.365\n",
      "import 0.286\n",
      "data 0.283\n",
      "wizard 0.27\n",
      "decimal 0.227\n",
      "conversion 0.224\n",
      "sql 0.217\n",
      "status 0.164\n",
      "file 0.147\n",
      "appropriately 0.142\n"
     ]
    }
   ],
   "source": [
    "idx=120\n",
    "keywords=get_keywords(idx)\n",
    "print_results(idx,keywords)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Word Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
